import os
import csv
from transformers import AutoTokenizer

# í˜„ì¬ ì´ .py íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "menu_db.csv")

# Huggingface tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-multilingual-cased")

def load_menu_csv(filepath=DB_PATH):
    menu_data = []
    with open(filepath, encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            menu_data.append(row)
    return menu_data

# í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_keywords(text):
    keywords = []
    if "í•œì‹" in text: keywords.append("í•œì‹")
    if "ì¤‘ì‹" in text: keywords.append("ì¤‘ì‹")
    if "ì¼ì‹" in text: keywords.append("ì¼ì‹")
    if "ì–‘ì‹" in text: keywords.append("ì–‘ì‹")

    if "ì°¨ê°€ìš´" in text or "ëƒ‰" in text: keywords.append("ì°¨ê°€ìš´")
    if "ë”°ëœ»í•œ" in text or "ëœ¨ê±°ìš´" in text or "êµ­ë¬¼" in text: keywords.append("ë”°ëœ»í•œ")

    if "ë§¤ìš´" in text or "ë§¤ì½¤" in text: keywords.append("ë§¤ì½¤í•œ")
    if "ìˆœí•œ" in text or "ì•ˆ ë§¤ìš´" in text: keywords.append("ìˆœí•œ")

    if "ë°¥" in text: keywords.append("ë°¥")
    if "ë©´" in text: keywords.append("ë©´")

    return keywords

# ë©”ë‰´ ì¶”ì²œ í•¨ìˆ˜
def recommend_menu(keywords, menu_data):
    results = []
    for item in menu_data:
        if all(k in item.values() for k in keywords):
            results.append(item)
    return results

# ì•ˆë‚´ ë©”ì‹œì§€
def print_style_guide():
    print("\n ê³ ë¥¼ ìˆ˜ ìˆëŠ” ìŒì‹ ìŠ¤íƒ€ì¼:")
    print("  - ì¢…ë¥˜: í•œì‹, ì¤‘ì‹, ì¼ì‹, ì–‘ì‹")
    print("  - ì˜¨ë„: ë”°ëœ»í•œ, ì°¨ê°€ìš´")
    print("  - ë§µê¸°: ë§¤ì½¤í•œ, ìˆœí•œ")
    print("  - ì£¼ì¬ë£Œ: ë°¥, ë©´")
    print("ì˜ˆì‹œ: 'ë”°ëœ»í•œ ë©´ ìš”ë¦¬, ì¤‘ì‹ì´ ë¨¹ê³  ì‹¶ì–´'")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

# ë©”ì¸ ì‹¤í–‰
def main():
    menu_data = load_menu_csv()
    print("ê°„ë‹¨í•œ ìŒì‹ ì¶”ì²œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.")
    print_style_guide()

    while True:
        user_input = input("ë¨¹ê³  ì‹¶ì€ ìŒì‹ ìŠ¤íƒ€ì¼ì„ ë§í•´ë³´ì„¸ìš”: ")

        if user_input.strip().lower() in ["ì¢…ë£Œ", "exit", "quit"]:
            print("ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break

        # Huggingface tokenizer í˜•ì‹ì  ì‚¬ìš©
        tokens = tokenizer.tokenize(user_input)
        print("ì…ë ¥ í† í°:", tokens)

        keywords = extract_keywords(user_input)
        if not keywords:
            print("ì…ë ¥ì—ì„œ ì¸ì‹ëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            continue

        matched = recommend_menu(keywords, menu_data)
        if matched:
            print("\nì¶”ì²œ ë©”ë‰´:")
            for item in matched:
                print(f"  - {item['name']} ({item['type']} / {item['temp']} / {item['spicy']} / {item['main']})")
        else:
            print("ì¡°ê±´ì— ë§ëŠ” ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜¢")

        print("\n" + "-"*50)
        print_style_guide()

# ì‹¤í–‰
if __name__ == "__main__":
    main()
